{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "DQN Agent on Colab.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/nikzadkhani/Famished-Geese/blob/main/tf-agents/DQN/DQN_Agent_on_Colab.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "T3VyafLP7Fmj"
      },
      "source": [
        "Load up kaggle environment from [gFootball Colab Example](https://github.com/google-research/football)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OTF-e0RN6wCw",
        "outputId": "36eb8ce4-d1b9-4508-9be2-f63330c3aa99"
      },
      "source": [
        " !apt-get update\n",
        " !apt-get install libsdl2-gfx-dev libsdl2-ttf-dev\n",
        "\n",
        "# # Make sure that the Branch in git clone and in wget call matches !!\n",
        " !git clone -b v2.9 https://github.com/google-research/football.git\n",
        " !mkdir -p football/third_party/gfootball_engine/lib\n",
        "\n",
        " !wget https://storage.googleapis.com/gfootball/prebuilt_gameplayfootball_v2.8.so -O football/third_party/gfootball_engine/lib/prebuilt_gameplayfootball.so\n",
        " !cd football && GFOOTBALL_USE_PREBUILT_SO=1 python3 -m pip install .\n",
        "\n",
        "!pip3 install tf_agents"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\r0% [Working]\r            \rHit:1 https://cloud.r-project.org/bin/linux/ubuntu bionic-cran40/ InRelease\n",
            "\r0% [Connecting to archive.ubuntu.com (91.189.88.152)] [Connecting to security.u\r0% [1 InRelease gpgv 3,626 B] [Connecting to archive.ubuntu.com (91.189.88.152)\r                                                                               \rIgn:2 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu1804/x86_64  InRelease\n",
            "Ign:3 https://developer.download.nvidia.com/compute/machine-learning/repos/ubuntu1804/x86_64  InRelease\n",
            "Hit:4 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu1804/x86_64  Release\n",
            "Hit:5 https://developer.download.nvidia.com/compute/machine-learning/repos/ubuntu1804/x86_64  Release\n",
            "Hit:6 http://security.ubuntu.com/ubuntu bionic-security InRelease\n",
            "Hit:7 http://ppa.launchpad.net/c2d4u.team/c2d4u4.0+/ubuntu bionic InRelease\n",
            "Hit:8 http://archive.ubuntu.com/ubuntu bionic InRelease\n",
            "Hit:10 http://archive.ubuntu.com/ubuntu bionic-updates InRelease\n",
            "Hit:11 http://archive.ubuntu.com/ubuntu bionic-backports InRelease\n",
            "Hit:12 http://ppa.launchpad.net/cran/libgit2/ubuntu bionic InRelease\n",
            "Hit:14 http://ppa.launchpad.net/deadsnakes/ppa/ubuntu bionic InRelease\n",
            "Hit:15 http://ppa.launchpad.net/graphics-drivers/ppa/ubuntu bionic InRelease\n",
            "Reading package lists... Done\n",
            "Reading package lists... Done\n",
            "Building dependency tree       \n",
            "Reading state information... Done\n",
            "libsdl2-gfx-dev is already the newest version (1.0.4+dfsg-1).\n",
            "libsdl2-ttf-dev is already the newest version (2.0.14+dfsg1-2).\n",
            "0 upgraded, 0 newly installed, 0 to remove and 88 not upgraded.\n",
            "Cloning into 'football'...\n",
            "remote: Enumerating objects: 2704, done.\u001b[K\n",
            "remote: Counting objects: 100% (20/20), done.\u001b[K\n",
            "remote: Compressing objects: 100% (20/20), done.\u001b[K\n",
            "remote: Total 2704 (delta 3), reused 7 (delta 0), pack-reused 2684\u001b[K\n",
            "Receiving objects: 100% (2704/2704), 27.01 MiB | 21.00 MiB/s, done.\n",
            "Resolving deltas: 100% (1524/1524), done.\n",
            "--2021-07-29 00:13:44--  https://storage.googleapis.com/gfootball/prebuilt_gameplayfootball_v2.8.so\n",
            "Resolving storage.googleapis.com (storage.googleapis.com)... 74.125.197.128, 74.125.142.128, 74.125.195.128, ...\n",
            "Connecting to storage.googleapis.com (storage.googleapis.com)|74.125.197.128|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 45403632 (43M) [application/octet-stream]\n",
            "Saving to: ‘football/third_party/gfootball_engine/lib/prebuilt_gameplayfootball.so’\n",
            "\n",
            "football/third_part 100%[===================>]  43.30M   101MB/s    in 0.4s    \n",
            "\n",
            "2021-07-29 00:13:45 (101 MB/s) - ‘football/third_party/gfootball_engine/lib/prebuilt_gameplayfootball.so’ saved [45403632/45403632]\n",
            "\n",
            "\u001b[33mWARNING: Ignoring invalid distribution -ensorflow-probability (/usr/local/lib/python3.7/dist-packages)\u001b[0m\n",
            "\u001b[33mWARNING: Ignoring invalid distribution -ensorflow-probability (/usr/local/lib/python3.7/dist-packages)\u001b[0m\n",
            "Processing /content/football\n",
            "\u001b[33m  DEPRECATION: A future pip version will change local packages to be built in-place without first copying to a temporary directory. We recommend you use --use-feature=in-tree-build to test your packages with this new behavior before it becomes the default.\n",
            "   pip 21.3 will remove support for this functionality. You can find discussion regarding this at https://github.com/pypa/pip/issues/7555.\u001b[0m\n",
            "Collecting pygame>=1.9.6\n",
            "  Downloading pygame-2.0.1-cp37-cp37m-manylinux1_x86_64.whl (11.8 MB)\n",
            "\u001b[K     |████████████████████████████████| 11.8 MB 128 kB/s \n",
            "\u001b[?25hRequirement already satisfied: opencv-python in /usr/local/lib/python3.7/dist-packages (from gfootball==2.9) (4.1.2.30)\n",
            "Requirement already satisfied: psutil in /usr/local/lib/python3.7/dist-packages (from gfootball==2.9) (5.4.8)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.7/dist-packages (from gfootball==2.9) (1.4.1)\n",
            "Requirement already satisfied: gym>=0.11.0 in /usr/local/lib/python3.7/dist-packages (from gfootball==2.9) (0.17.3)\n",
            "Requirement already satisfied: absl-py in /usr/local/lib/python3.7/dist-packages (from gfootball==2.9) (0.12.0)\n",
            "Requirement already satisfied: wheel in /usr/local/lib/python3.7/dist-packages (from gfootball==2.9) (0.36.2)\n",
            "Requirement already satisfied: cloudpickle<1.7.0,>=1.2.0 in /usr/local/lib/python3.7/dist-packages (from gym>=0.11.0->gfootball==2.9) (1.3.0)\n",
            "Requirement already satisfied: numpy>=1.10.4 in /usr/local/lib/python3.7/dist-packages (from gym>=0.11.0->gfootball==2.9) (1.19.5)\n",
            "Requirement already satisfied: pyglet<=1.5.0,>=1.4.0 in /usr/local/lib/python3.7/dist-packages (from gym>=0.11.0->gfootball==2.9) (1.5.0)\n",
            "Requirement already satisfied: future in /usr/local/lib/python3.7/dist-packages (from pyglet<=1.5.0,>=1.4.0->gym>=0.11.0->gfootball==2.9) (0.16.0)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from absl-py->gfootball==2.9) (1.15.0)\n",
            "Building wheels for collected packages: gfootball\n",
            "  Building wheel for gfootball (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for gfootball: filename=gfootball-2.9-cp37-cp37m-linux_x86_64.whl size=38782272 sha256=70419c9c3d6e49d3b4c567ccf4022af59898b928b7e40b7f4b036dde52c73d5a\n",
            "  Stored in directory: /tmp/pip-ephem-wheel-cache-z7l_nfkd/wheels/bb/c2/92/82a23d0c207f5497a23f4316675eb1629e6be474bd2c3be61a\n",
            "Successfully built gfootball\n",
            "\u001b[33mWARNING: Ignoring invalid distribution -ensorflow-probability (/usr/local/lib/python3.7/dist-packages)\u001b[0m\n",
            "Installing collected packages: pygame, gfootball\n",
            "\u001b[33mWARNING: Ignoring invalid distribution -ensorflow-probability (/usr/local/lib/python3.7/dist-packages)\u001b[0m\n",
            "\u001b[33mWARNING: Ignoring invalid distribution -ensorflow-probability (/usr/local/lib/python3.7/dist-packages)\u001b[0m\n",
            "Successfully installed gfootball-2.9 pygame-2.0.1\n",
            "\u001b[33mWARNING: Ignoring invalid distribution -ensorflow-probability (/usr/local/lib/python3.7/dist-packages)\u001b[0m\n",
            "\u001b[33mWARNING: Ignoring invalid distribution -ensorflow-probability (/usr/local/lib/python3.7/dist-packages)\u001b[0m\n",
            "Collecting tf_agents\n",
            "  Using cached tf_agents-0.8.0-py3-none-any.whl (1.2 MB)\n",
            "Requirement already satisfied: wrapt>=1.11.1 in /usr/local/lib/python3.7/dist-packages (from tf_agents) (1.12.1)\n",
            "Requirement already satisfied: cloudpickle>=1.3 in /usr/local/lib/python3.7/dist-packages (from tf_agents) (1.3.0)\n",
            "Collecting tensorflow-probability==0.12.2\n",
            "  Using cached tensorflow_probability-0.12.2-py2.py3-none-any.whl (4.8 MB)\n",
            "Requirement already satisfied: numpy>=1.13.3 in /usr/local/lib/python3.7/dist-packages (from tf_agents) (1.19.5)\n",
            "Requirement already satisfied: gym>=0.17.0 in /usr/local/lib/python3.7/dist-packages (from tf_agents) (0.17.3)\n",
            "Requirement already satisfied: absl-py>=0.6.1 in /usr/local/lib/python3.7/dist-packages (from tf_agents) (0.12.0)\n",
            "Requirement already satisfied: protobuf>=3.11.3 in /usr/local/lib/python3.7/dist-packages (from tf_agents) (3.17.3)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.7/dist-packages (from tf_agents) (3.7.4.3)\n",
            "Requirement already satisfied: gin-config>=0.4.0 in /usr/local/lib/python3.7/dist-packages (from tf_agents) (0.4.0)\n",
            "Requirement already satisfied: six>=1.10.0 in /usr/local/lib/python3.7/dist-packages (from tf_agents) (1.15.0)\n",
            "Requirement already satisfied: dm-tree in /usr/local/lib/python3.7/dist-packages (from tensorflow-probability==0.12.2->tf_agents) (0.1.6)\n",
            "Requirement already satisfied: gast>=0.3.2 in /usr/local/lib/python3.7/dist-packages (from tensorflow-probability==0.12.2->tf_agents) (0.4.0)\n",
            "Requirement already satisfied: decorator in /usr/local/lib/python3.7/dist-packages (from tensorflow-probability==0.12.2->tf_agents) (4.4.2)\n",
            "Requirement already satisfied: pyglet<=1.5.0,>=1.4.0 in /usr/local/lib/python3.7/dist-packages (from gym>=0.17.0->tf_agents) (1.5.0)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.7/dist-packages (from gym>=0.17.0->tf_agents) (1.4.1)\n",
            "Requirement already satisfied: future in /usr/local/lib/python3.7/dist-packages (from pyglet<=1.5.0,>=1.4.0->gym>=0.17.0->tf_agents) (0.16.0)\n",
            "\u001b[33mWARNING: Ignoring invalid distribution -ensorflow-probability (/usr/local/lib/python3.7/dist-packages)\u001b[0m\n",
            "Installing collected packages: tensorflow-probability, tf-agents\n",
            "\u001b[33mWARNING: Ignoring invalid distribution -ensorflow-probability (/usr/local/lib/python3.7/dist-packages)\u001b[0m\n",
            "\u001b[33mWARNING: Ignoring invalid distribution -ensorflow-probability (/usr/local/lib/python3.7/dist-packages)\u001b[0m\n",
            "Successfully installed tensorflow-probability-0.12.2 tf-agents-0.8.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "K6Ot_fVBnNW5",
        "outputId": "19e23d08-aba3-4cbb-f41f-0679deb76b5c"
      },
      "source": [
        "!pip install kaggle-environments"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\u001b[33mWARNING: Ignoring invalid distribution -ensorflow-probability (/usr/local/lib/python3.7/dist-packages)\u001b[0m\n",
            "\u001b[33mWARNING: Ignoring invalid distribution -ensorflow-probability (/usr/local/lib/python3.7/dist-packages)\u001b[0m\n",
            "Collecting kaggle-environments\n",
            "  Downloading kaggle_environments-1.8.3-py2.py3-none-any.whl (676 kB)\n",
            "\u001b[K     |████████████████████████████████| 676 kB 7.6 MB/s \n",
            "\u001b[?25hCollecting jsonschema>=3.0.1\n",
            "  Downloading jsonschema-3.2.0-py2.py3-none-any.whl (56 kB)\n",
            "\u001b[K     |████████████████████████████████| 56 kB 4.6 MB/s \n",
            "\u001b[?25hRequirement already satisfied: setuptools in /usr/local/lib/python3.7/dist-packages (from jsonschema>=3.0.1->kaggle-environments) (57.2.0)\n",
            "Requirement already satisfied: attrs>=17.4.0 in /usr/local/lib/python3.7/dist-packages (from jsonschema>=3.0.1->kaggle-environments) (21.2.0)\n",
            "Requirement already satisfied: six>=1.11.0 in /usr/local/lib/python3.7/dist-packages (from jsonschema>=3.0.1->kaggle-environments) (1.15.0)\n",
            "Requirement already satisfied: pyrsistent>=0.14.0 in /usr/local/lib/python3.7/dist-packages (from jsonschema>=3.0.1->kaggle-environments) (0.18.0)\n",
            "Requirement already satisfied: importlib-metadata in /usr/local/lib/python3.7/dist-packages (from jsonschema>=3.0.1->kaggle-environments) (4.6.1)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata->jsonschema>=3.0.1->kaggle-environments) (3.5.0)\n",
            "Requirement already satisfied: typing-extensions>=3.6.4 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata->jsonschema>=3.0.1->kaggle-environments) (3.7.4.3)\n",
            "\u001b[33mWARNING: Ignoring invalid distribution -ensorflow-probability (/usr/local/lib/python3.7/dist-packages)\u001b[0m\n",
            "Installing collected packages: jsonschema, kaggle-environments\n",
            "  Attempting uninstall: jsonschema\n",
            "\u001b[33m    WARNING: Ignoring invalid distribution -ensorflow-probability (/usr/local/lib/python3.7/dist-packages)\u001b[0m\n",
            "    Found existing installation: jsonschema 2.6.0\n",
            "    Uninstalling jsonschema-2.6.0:\n",
            "      Successfully uninstalled jsonschema-2.6.0\n",
            "\u001b[33mWARNING: Ignoring invalid distribution -ensorflow-probability (/usr/local/lib/python3.7/dist-packages)\u001b[0m\n",
            "\u001b[33mWARNING: Ignoring invalid distribution -ensorflow-probability (/usr/local/lib/python3.7/dist-packages)\u001b[0m\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "nbclient 0.5.3 requires jupyter-client>=6.1.5, but you have jupyter-client 5.3.5 which is incompatible.\u001b[0m\n",
            "Successfully installed jsonschema-3.2.0 kaggle-environments-1.8.3\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "G9O-E8IVSKHf",
        "outputId": "3072ae2a-acbf-4bd9-cf8a-bdb6a4def463"
      },
      "source": [
        "\n",
        "from kaggle_environments.envs.hungry_geese.hungry_geese import (Observation,\n",
        "                                                                Configuration,\n",
        "                                                                Action,\n",
        "                                                                row_col,\n",
        "                                                                translate,\n",
        "                                                                greedy_agent)\n",
        "from kaggle_environments import evaluate, make, utils\n",
        "\n",
        "import numpy as np\n",
        "import random\n",
        "from tqdm import tqdm\n",
        "import abc\n",
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "from tf_agents.environments import py_environment\n",
        "from tf_agents.environments import tf_environment\n",
        "from tf_agents.environments import tf_py_environment\n",
        "from tf_agents.environments import utils\n",
        "from tf_agents.specs import array_spec\n",
        "from tf_agents.environments import wrappers\n",
        "from tf_agents.environments import suite_gym\n",
        "from tf_agents.trajectories import time_step as ts\n",
        "\n",
        "tf.compat.v1.enable_v2_behavior()\n",
        "\n",
        "\n",
        "class TFHungryGoose(py_environment.PyEnvironment):\n",
        "    def __init__(self):\n",
        "        env = make(\"hungry_geese\")\n",
        "        self.trainer = env.train([None, greedy_agent, greedy_agent, greedy_agent])\n",
        "        obs = self.trainer.reset()\n",
        "        self._action_spec = array_spec.BoundedArraySpec(\n",
        "            shape=(), dtype=np.int32, minimum=0, maximum=3, name='action')\n",
        "        self._observation_spec = array_spec.BoundedArraySpec(\n",
        "            shape=(1, 7, 11, 1), dtype=np.float32, minimum=0, maximum=10, name='observation')\n",
        "        self._state = self.create_grid_from_geese_position(obs)\n",
        "        self._episode_ended = False\n",
        "        self.action_name_mapping = {0: 'NORTH', 1: 'SOUTH', 2: 'EAST', 3: 'WEST'}\n",
        "\n",
        "    def create_grid_from_geese_position(self, obs, grid_cols=11, grid_rows=7):\n",
        "        geese_position = obs.geese\n",
        "        foods = obs.food\n",
        "        my_index = obs.index\n",
        "        matrix = np.zeros((grid_rows, grid_cols))\n",
        "        goose_id = [1, 2, 3, 4]\n",
        "        for i, goose_position in enumerate(geese_position):\n",
        "            for j, pos in enumerate(goose_position):\n",
        "                row, col = row_col(pos, grid_cols)\n",
        "                if j == 0:\n",
        "                    if i != my_index:\n",
        "                        matrix[row][col] = 6\n",
        "                    else:\n",
        "                        matrix[row][col] = 7\n",
        "                else:\n",
        "                    matrix[row][col] = goose_id[i]\n",
        "        np.put(matrix, foods, [5])\n",
        "        return matrix.reshape(1, 7, 11, 1).astype('float32')\n",
        "\n",
        "    def action_spec(self):\n",
        "        return self._action_spec\n",
        "\n",
        "    def observation_spec(self):\n",
        "        return self._observation_spec\n",
        "\n",
        "    def _reset(self):\n",
        "        obs = self.trainer.reset()\n",
        "        self._state = self.create_grid_from_geese_position(obs)\n",
        "        self._episode_ended = False\n",
        "        return ts.restart(self._state)\n",
        "\n",
        "    def __reward_manager(self, reward, step, geese):\n",
        "      #The reward is calculated as the current turn + goose length.\n",
        "      return step+ len(geese[0])\n",
        "\n",
        "\n",
        "\n",
        "      \"\"\" old reward version\n",
        "      if step == 1 and (reward != 0):\n",
        "          return 50\n",
        "      elif (reward == 0) or (len(geese[0]) == 0):\n",
        "          return -400\n",
        "      elif (max([len(goose) for goose in geese[1:]]) == 0) and (reward != 0):\n",
        "          return 1000\n",
        "      elif (reward % 100) == 0:\n",
        "          return 50\n",
        "      else:\n",
        "          return 100\"\"\"\n",
        "\n",
        "    def _step(self, action):\n",
        "        if self._episode_ended:\n",
        "            return self.reset()\n",
        "        action = self.action_name_mapping[int(action)]\n",
        "        obs, reward, self._episode_ended, info = self.trainer.step(action)\n",
        "        reward = self.__reward_manager(reward, obs.step, obs.geese)\n",
        "        self._state = self.create_grid_from_geese_position(obs)\n",
        "        if self._episode_ended:\n",
        "            return ts.termination(self._state, reward)\n",
        "        else:\n",
        "            return ts.transition(self._state, reward=reward, discount=1.0)\n",
        "print(\"Compiled\")\n"
      ],
      "execution_count": 117,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Compiled\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2rUzMlE5SR2W",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "50987ba5-a6d5-4879-ec63-6b772c57072d"
      },
      "source": [
        "%load_ext tensorboard\n"
      ],
      "execution_count": 118,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "The tensorboard extension is already loaded. To reload it, use:\n",
            "  %reload_ext tensorboard\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SKk4wAJbSWm3",
        "outputId": "199d7870-310e-4344-f33d-a402a14a3498"
      },
      "source": [
        "from datetime import datetime\n",
        "from packaging import version\n",
        "\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "\n",
        "print(\"TensorFlow version: \", tf.__version__)\n",
        "assert version.parse(tf.__version__).release[0] >= 2, \\\n",
        "    \"This notebook requires TensorFlow 2.0 or above.\""
      ],
      "execution_count": 119,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "TensorFlow version:  2.5.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "mKpRoeTOSrZO",
        "outputId": "34e2d2a7-17ab-429f-84d1-7a749762013c"
      },
      "source": [
        "import tensorboard\n",
        "tensorboard.__version__"
      ],
      "execution_count": 120,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'2.5.0'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 120
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VCRa7n2eStpq"
      },
      "source": [
        "# Clear any logs from previous runs\n",
        "!rm -rf ./logs/ "
      ],
      "execution_count": 121,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "n3jlTRuGSvS0"
      },
      "source": [
        "import tensorflow as tf\n",
        "from tf_agents.networks import sequential\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense, Dropout, Conv2D, Flatten,LeakyReLU\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "# The QNetwork model\n",
        "# used leaky relu to address vanishing gradient\n",
        "model = sequential.Sequential([\n",
        "    Conv2D(64, kernel_size=3, activation=LeakyReLU()),\n",
        "    Conv2D(32, kernel_size=3, activation=LeakyReLU()),\n",
        "    Flatten(),\n",
        "    Dense(48, activation=\"relu\"),\n",
        "    Dense(24, activation=\"relu\"),\n",
        "    Dense(4, activation=None),\n",
        "])"
      ],
      "execution_count": 124,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YqwF0WgAV4Os"
      },
      "source": [
        ""
      ],
      "execution_count": 124,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9yIzKqrYS5Mq"
      },
      "source": [
        "## test the env on sample episodes\n",
        "env = TFHungryGoose()\n",
        "utils.validate_py_environment(env, episodes=5)"
      ],
      "execution_count": 125,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CaZbbBGpXmQ4",
        "outputId": "3b689fbb-d729-4f92-fe16-50049d6dc433"
      },
      "source": [
        "!pip install tf_agents"
      ],
      "execution_count": 126,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\u001b[33mWARNING: Ignoring invalid distribution -ensorflow-probability (/usr/local/lib/python3.7/dist-packages)\u001b[0m\n",
            "\u001b[33mWARNING: Ignoring invalid distribution -ensorflow-probability (/usr/local/lib/python3.7/dist-packages)\u001b[0m\n",
            "Requirement already satisfied: tf_agents in /usr/local/lib/python3.7/dist-packages (0.8.0)\n",
            "Requirement already satisfied: gym>=0.17.0 in /usr/local/lib/python3.7/dist-packages (from tf_agents) (0.17.3)\n",
            "Requirement already satisfied: wrapt>=1.11.1 in /usr/local/lib/python3.7/dist-packages (from tf_agents) (1.12.1)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.7/dist-packages (from tf_agents) (3.7.4.3)\n",
            "Requirement already satisfied: gin-config>=0.4.0 in /usr/local/lib/python3.7/dist-packages (from tf_agents) (0.4.0)\n",
            "Requirement already satisfied: tensorflow-probability==0.12.2 in /usr/local/lib/python3.7/dist-packages (from tf_agents) (0.12.2)\n",
            "Requirement already satisfied: absl-py>=0.6.1 in /usr/local/lib/python3.7/dist-packages (from tf_agents) (0.12.0)\n",
            "Requirement already satisfied: numpy>=1.13.3 in /usr/local/lib/python3.7/dist-packages (from tf_agents) (1.19.5)\n",
            "Requirement already satisfied: six>=1.10.0 in /usr/local/lib/python3.7/dist-packages (from tf_agents) (1.15.0)\n",
            "Requirement already satisfied: protobuf>=3.11.3 in /usr/local/lib/python3.7/dist-packages (from tf_agents) (3.17.3)\n",
            "Requirement already satisfied: cloudpickle>=1.3 in /usr/local/lib/python3.7/dist-packages (from tf_agents) (1.3.0)\n",
            "Requirement already satisfied: dm-tree in /usr/local/lib/python3.7/dist-packages (from tensorflow-probability==0.12.2->tf_agents) (0.1.6)\n",
            "Requirement already satisfied: decorator in /usr/local/lib/python3.7/dist-packages (from tensorflow-probability==0.12.2->tf_agents) (4.4.2)\n",
            "Requirement already satisfied: gast>=0.3.2 in /usr/local/lib/python3.7/dist-packages (from tensorflow-probability==0.12.2->tf_agents) (0.4.0)\n",
            "Requirement already satisfied: pyglet<=1.5.0,>=1.4.0 in /usr/local/lib/python3.7/dist-packages (from gym>=0.17.0->tf_agents) (1.5.0)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.7/dist-packages (from gym>=0.17.0->tf_agents) (1.4.1)\n",
            "Requirement already satisfied: future in /usr/local/lib/python3.7/dist-packages (from pyglet<=1.5.0,>=1.4.0->gym>=0.17.0->tf_agents) (0.16.0)\n",
            "\u001b[33mWARNING: Ignoring invalid distribution -ensorflow-probability (/usr/local/lib/python3.7/dist-packages)\u001b[0m\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oG_HrVEJgA7j"
      },
      "source": [
        "num_iterations = 200000 # @param {type:\"integer\"}\n",
        "\n",
        "initial_collect_steps = 100  # @param {type:\"integer\"} \n",
        "collect_steps_per_iteration = 25  # @param {type:\"integer\"}\n",
        "replay_buffer_max_length = 100000  # @param {type:\"integer\"}\n",
        "\n",
        "batch_size = 64  # @param {type:\"integer\"}\n",
        "learning_rate = 1e-3  # @param {type:\"number\"}\n",
        "log_interval = 200  # @param {type:\"integer\"}\n",
        "\n",
        "num_eval_episodes = 200  # @param {type:\"integer\"}\n",
        "eval_interval = 200  # @param {type:\"integer\"}"
      ],
      "execution_count": 127,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WJzrxBGNTNOv"
      },
      "source": [
        "from tf_agents.train.utils import strategy_utils, train_utils\n",
        "from tf_agents.agents.dqn import dqn_agent\n",
        "from tf_agents.environments import suite_gym\n",
        "from tf_agents.environments import tf_py_environment\n",
        "from tf_agents.eval import metric_utils\n",
        "from tf_agents.metrics import tf_metrics\n",
        "from tf_agents.networks import sequential\n",
        "from tf_agents.policies import random_tf_policy\n",
        "from tf_agents.replay_buffers import tf_uniform_replay_buffer\n",
        "from tf_agents.trajectories import trajectory\n",
        "from tf_agents.specs import tensor_spec\n",
        "from tf_agents.utils import common\n",
        "\n",
        "train_env = tf_py_environment.TFPyEnvironment(TFHungryGoose())\n",
        "eval_env = tf_py_environment.TFPyEnvironment(TFHungryGoose())\n",
        "\n",
        "# set the optimizer\n",
        "optimizer = tf.keras.optimizers.Adam(learning_rate=0.001)\n",
        "\n",
        "# step counter\n",
        "use_gpu = False\n",
        "\n",
        "strategy = strategy_utils.get_strategy(tpu=False, use_gpu=use_gpu)\n",
        "\n",
        "# create the DQN agent\n",
        "with strategy.scope():\n",
        "  train_step = train_utils.create_train_step()\n",
        "  train_step_counter = tf.Variable(0)\n",
        "  agent = dqn_agent.DqnAgent(\n",
        "    train_env.time_step_spec(),\n",
        "    train_env.action_spec(),\n",
        "    q_network=model,\n",
        "    optimizer=optimizer,\n",
        "    td_errors_loss_fn=common.element_wise_squared_loss,\n",
        "    train_step_counter=train_step_counter)\n",
        "\n",
        "  agent.initialize()"
      ],
      "execution_count": 128,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pcwVjXDJWg7i",
        "outputId": "a2ee8868-d821-4417-d49c-a5409669dece"
      },
      "source": [
        "print('Observation Spec:')\n",
        "print(env.time_step_spec().observation)"
      ],
      "execution_count": 129,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Observation Spec:\n",
            "BoundedArraySpec(shape=(1, 7, 11, 1), dtype=dtype('float32'), name='observation', minimum=0.0, maximum=10.0)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-8fE1u6OiEo2",
        "outputId": "dacf544b-5e17-4c18-94a0-d346532699e0"
      },
      "source": [
        "print('Reward Spec:')\n",
        "print(env.time_step_spec().reward)"
      ],
      "execution_count": 130,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Reward Spec:\n",
            "ArraySpec(shape=(), dtype=dtype('float32'), name='reward')\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KavCESs0iErt",
        "outputId": "f9c9b7c4-0a3f-40c6-fa51-fb35897de882"
      },
      "source": [
        "print('Action Spec:')\n",
        "print(env.action_spec())"
      ],
      "execution_count": 131,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Action Spec:\n",
            "BoundedArraySpec(shape=(), dtype=dtype('int32'), name='action', minimum=0, maximum=3)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NxbUv_iiiEug",
        "outputId": "dc243a03-c153-4f36-82e4-f6c5ea7ddd72"
      },
      "source": [
        "time_step = env.reset()\n",
        "print('Time step:')\n",
        "print(time_step)\n",
        "\n",
        "action = np.array(1, dtype=np.int32)\n",
        "\n",
        "next_time_step = env.step(action)\n",
        "print('Next time step:')\n",
        "print(next_time_step)"
      ],
      "execution_count": 132,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Time step:\n",
            "TimeStep(\n",
            "{'discount': array(1., dtype=float32),\n",
            " 'observation': array([[[[0.],\n",
            "         [0.],\n",
            "         [0.],\n",
            "         [0.],\n",
            "         [7.],\n",
            "         [6.],\n",
            "         [0.],\n",
            "         [0.],\n",
            "         [0.],\n",
            "         [0.],\n",
            "         [0.]],\n",
            "\n",
            "        [[0.],\n",
            "         [5.],\n",
            "         [0.],\n",
            "         [0.],\n",
            "         [0.],\n",
            "         [0.],\n",
            "         [0.],\n",
            "         [0.],\n",
            "         [0.],\n",
            "         [0.],\n",
            "         [0.]],\n",
            "\n",
            "        [[0.],\n",
            "         [0.],\n",
            "         [0.],\n",
            "         [0.],\n",
            "         [0.],\n",
            "         [0.],\n",
            "         [6.],\n",
            "         [0.],\n",
            "         [0.],\n",
            "         [0.],\n",
            "         [0.]],\n",
            "\n",
            "        [[0.],\n",
            "         [0.],\n",
            "         [0.],\n",
            "         [0.],\n",
            "         [0.],\n",
            "         [0.],\n",
            "         [0.],\n",
            "         [0.],\n",
            "         [0.],\n",
            "         [0.],\n",
            "         [0.]],\n",
            "\n",
            "        [[0.],\n",
            "         [0.],\n",
            "         [0.],\n",
            "         [0.],\n",
            "         [0.],\n",
            "         [0.],\n",
            "         [0.],\n",
            "         [0.],\n",
            "         [5.],\n",
            "         [0.],\n",
            "         [0.]],\n",
            "\n",
            "        [[0.],\n",
            "         [0.],\n",
            "         [0.],\n",
            "         [0.],\n",
            "         [6.],\n",
            "         [0.],\n",
            "         [0.],\n",
            "         [0.],\n",
            "         [0.],\n",
            "         [0.],\n",
            "         [0.]],\n",
            "\n",
            "        [[0.],\n",
            "         [0.],\n",
            "         [0.],\n",
            "         [0.],\n",
            "         [0.],\n",
            "         [0.],\n",
            "         [0.],\n",
            "         [0.],\n",
            "         [0.],\n",
            "         [0.],\n",
            "         [0.]]]], dtype=float32),\n",
            " 'reward': array(0., dtype=float32),\n",
            " 'step_type': array(0, dtype=int32)})\n",
            "Next time step:\n",
            "TimeStep(\n",
            "{'discount': array(1., dtype=float32),\n",
            " 'observation': array([[[[0.],\n",
            "         [0.],\n",
            "         [0.],\n",
            "         [0.],\n",
            "         [0.],\n",
            "         [0.],\n",
            "         [0.],\n",
            "         [0.],\n",
            "         [0.],\n",
            "         [0.],\n",
            "         [0.]],\n",
            "\n",
            "        [[0.],\n",
            "         [5.],\n",
            "         [0.],\n",
            "         [0.],\n",
            "         [7.],\n",
            "         [0.],\n",
            "         [0.],\n",
            "         [0.],\n",
            "         [0.],\n",
            "         [0.],\n",
            "         [0.]],\n",
            "\n",
            "        [[0.],\n",
            "         [0.],\n",
            "         [0.],\n",
            "         [0.],\n",
            "         [0.],\n",
            "         [0.],\n",
            "         [0.],\n",
            "         [6.],\n",
            "         [0.],\n",
            "         [0.],\n",
            "         [0.]],\n",
            "\n",
            "        [[0.],\n",
            "         [0.],\n",
            "         [0.],\n",
            "         [0.],\n",
            "         [0.],\n",
            "         [0.],\n",
            "         [0.],\n",
            "         [0.],\n",
            "         [0.],\n",
            "         [0.],\n",
            "         [0.]],\n",
            "\n",
            "        [[0.],\n",
            "         [0.],\n",
            "         [0.],\n",
            "         [0.],\n",
            "         [6.],\n",
            "         [0.],\n",
            "         [0.],\n",
            "         [0.],\n",
            "         [5.],\n",
            "         [0.],\n",
            "         [0.]],\n",
            "\n",
            "        [[0.],\n",
            "         [0.],\n",
            "         [0.],\n",
            "         [0.],\n",
            "         [0.],\n",
            "         [0.],\n",
            "         [0.],\n",
            "         [0.],\n",
            "         [0.],\n",
            "         [0.],\n",
            "         [0.]],\n",
            "\n",
            "        [[0.],\n",
            "         [0.],\n",
            "         [0.],\n",
            "         [0.],\n",
            "         [0.],\n",
            "         [6.],\n",
            "         [0.],\n",
            "         [0.],\n",
            "         [0.],\n",
            "         [0.],\n",
            "         [0.]]]], dtype=float32),\n",
            " 'reward': array(2., dtype=float32),\n",
            " 'step_type': array(1, dtype=int32)})\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0IKfVBxriEww"
      },
      "source": [
        "eval_policy = agent.policy\n",
        "collect_policy = agent.collect_policy"
      ],
      "execution_count": 133,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "F01uAxnNiEzm"
      },
      "source": [
        "random_policy = random_tf_policy.RandomTFPolicy(train_env.time_step_spec(),\n",
        "                                                train_env.action_spec())"
      ],
      "execution_count": 134,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UMdGe7uqia-v"
      },
      "source": [
        "time_step = train_env.reset()"
      ],
      "execution_count": 135,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Y85-kEOGidgn",
        "outputId": "279ad852-86e4-498e-c5a8-e3907e2940db"
      },
      "source": [
        "random_policy.action(time_step)"
      ],
      "execution_count": 136,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "PolicyStep(action=<tf.Tensor: shape=(1,), dtype=int32, numpy=array([3], dtype=int32)>, state=(), info=())"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 136
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ITNvBWc8VzaM"
      },
      "source": [
        "#@test {\"skip\": true}\n",
        "def compute_avg_return(environment, policy, num_episodes=10):\n",
        "\n",
        "  total_return = 0.0\n",
        "  for _ in range(num_episodes):\n",
        "\n",
        "    time_step = environment.reset()\n",
        "    episode_return = 0.0\n",
        "\n",
        "    while not time_step.is_last():\n",
        "      action_step = policy.action(time_step)\n",
        "      time_step = environment.step(action_step.action)\n",
        "      episode_return += time_step.reward\n",
        "    total_return += episode_return\n",
        "\n",
        "  avg_return = total_return / num_episodes\n",
        "  return avg_return.numpy()[0]\n",
        "\n",
        "\n",
        "# See also the metrics module for standard implementations of different metrics.\n",
        "# https://github.com/tensorflow/agents/tree/master/tf_agents/metrics"
      ],
      "execution_count": 137,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "S0A4NPooi3ed",
        "outputId": "2432f389-2538-43a9-e4aa-860c26709c6f"
      },
      "source": [
        "compute_avg_return(eval_env, random_policy, num_eval_episodes)"
      ],
      "execution_count": 138,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "23.23"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 138
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KRGU32IiW51f"
      },
      "source": [
        "replay_buffer = tf_uniform_replay_buffer.TFUniformReplayBuffer(\n",
        "    data_spec=agent.collect_data_spec,\n",
        "    batch_size=train_env.batch_size,\n",
        "    max_length=replay_buffer_max_length)"
      ],
      "execution_count": 139,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "S___vipnW_da",
        "outputId": "441563d5-ab2a-441d-8b93-3ccd9dbd1717"
      },
      "source": [
        "agent.collect_data_spec"
      ],
      "execution_count": 140,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Trajectory(\n",
              "{'action': BoundedTensorSpec(shape=(), dtype=tf.int32, name='action', minimum=array(0, dtype=int32), maximum=array(3, dtype=int32)),\n",
              " 'discount': BoundedTensorSpec(shape=(), dtype=tf.float32, name='discount', minimum=array(0., dtype=float32), maximum=array(1., dtype=float32)),\n",
              " 'next_step_type': TensorSpec(shape=(), dtype=tf.int32, name='step_type'),\n",
              " 'observation': BoundedTensorSpec(shape=(1, 7, 11, 1), dtype=tf.float32, name='observation', minimum=array(0., dtype=float32), maximum=array(10., dtype=float32)),\n",
              " 'policy_info': (),\n",
              " 'reward': TensorSpec(shape=(), dtype=tf.float32, name='reward'),\n",
              " 'step_type': TensorSpec(shape=(), dtype=tf.int32, name='step_type')})"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 140
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TZFTr_b3i-Mb",
        "outputId": "53501203-d2cf-46f0-e9ff-4a1cb7eab0c1"
      },
      "source": [
        "agent.collect_data_spec._fields"
      ],
      "execution_count": 141,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "('step_type',\n",
              " 'observation',\n",
              " 'action',\n",
              " 'policy_info',\n",
              " 'next_step_type',\n",
              " 'reward',\n",
              " 'discount')"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 141
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3f5-6fekjBsc"
      },
      "source": [
        "#@test {\"skip\": true}\n",
        "def collect_step(environment, policy, buffer):\n",
        "  time_step = environment.current_time_step()\n",
        "  action_step = policy.action(time_step)\n",
        "  next_time_step = environment.step(action_step.action)\n",
        "  traj = trajectory.from_transition(time_step, action_step, next_time_step)\n",
        "\n",
        "  # Add trajectory to the replay buffer\n",
        "  buffer.add_batch(traj)\n",
        "\n",
        "def collect_data(env, policy, buffer, steps):\n",
        "  for _ in range(steps):\n",
        "    collect_step(env, policy, buffer)\n",
        "\n",
        "collect_data(train_env,agent.policy, replay_buffer, initial_collect_steps)\n",
        "\n",
        "# This loop is so common in RL, that we provide standard implementations. \n",
        "# For more details see tutorial 4 or the drivers module.\n",
        "# https://github.com/tensorflow/agents/blob/master/docs/tutorials/4_drivers_tutorial.ipynb \n",
        "# https://www.tensorflow.org/agents/api_docs/python/tf_agents/drivers"
      ],
      "execution_count": 142,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VqkNZcrpjH-C",
        "outputId": "98d4b9b3-5d16-4d33-a342-7d82b1808fc2"
      },
      "source": [
        "dataset = replay_buffer.as_dataset(\n",
        "    num_parallel_calls=3, \n",
        "    sample_batch_size=batch_size, \n",
        "    num_steps=2).prefetch(3)\n",
        "\n",
        "\n",
        "dataset"
      ],
      "execution_count": 143,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<PrefetchDataset shapes: (Trajectory(\n",
              "{action: (64, 2),\n",
              " discount: (64, 2),\n",
              " next_step_type: (64, 2),\n",
              " observation: (64, 2, 1, 7, 11, 1),\n",
              " policy_info: (),\n",
              " reward: (64, 2),\n",
              " step_type: (64, 2)}), BufferInfo(ids=(64, 2), probabilities=(64,))), types: (Trajectory(\n",
              "{action: tf.int32,\n",
              " discount: tf.float32,\n",
              " next_step_type: tf.int32,\n",
              " observation: tf.float32,\n",
              " policy_info: (),\n",
              " reward: tf.float32,\n",
              " step_type: tf.int32}), BufferInfo(ids=tf.int64, probabilities=tf.float32))>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 143
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rvP2IU6UjO_O",
        "outputId": "c2e175a3-8868-4ed0-e924-39aec11c52ca"
      },
      "source": [
        "iterator = iter(dataset)\n",
        "print(iterator)"
      ],
      "execution_count": 144,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "<tensorflow.python.data.ops.iterator_ops.OwnedIterator object at 0x7f7a3a016250>\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kQHDjFqMjZAG",
        "outputId": "82b666c5-b6a9-4a53-e148-34b5f61fdade"
      },
      "source": [
        "#@test {\"skip\": true}\n",
        "try:\n",
        "  %%time\n",
        "except:\n",
        "  pass\n",
        "\n",
        "# (Optional) Optimize by wrapping some of the code in a graph using TF function.\n",
        "agent.train = common.function(agent.train)\n",
        "\n",
        "# Reset the train step\n",
        "agent.train_step_counter.assign(0)\n",
        "\n",
        "# Evaluate the agent's policy once before training.\n",
        "avg_return = compute_avg_return(eval_env, agent.policy, num_eval_episodes)\n",
        "returns = [avg_return]\n",
        "\n",
        "for _ in range(num_iterations):\n",
        "  #print(_)\n",
        "  # Collect a few steps using collect_policy and save to the replay buffer.\n",
        "  collect_data(train_env, agent.collect_policy, replay_buffer, collect_steps_per_iteration)\n",
        "\n",
        "  # Sample a batch of data from the buffer and update the agent's network.\n",
        "  experience, unused_info = next(iterator)\n",
        "  train_loss = agent.train(experience).loss\n",
        "\n",
        "  step = agent.train_step_counter.numpy()\n",
        "\n",
        "  if step % log_interval == 0:\n",
        "    print('step = {0}: loss = {1}'.format(step, train_loss))\n",
        "\n",
        "  if step % eval_interval == 0:\n",
        "    avg_return = compute_avg_return(eval_env, agent.policy, num_eval_episodes)\n",
        "    print('step = {0}: Average Return = {1}'.format(step, avg_return))\n",
        "    returns.append(avg_return)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "CPU times: user 3 µs, sys: 0 ns, total: 3 µs\n",
            "Wall time: 6.44 µs\n",
            "step = 200: loss = 4700.359375\n",
            "step = 200: Average Return = 286.2550048828125\n",
            "step = 400: loss = 2219.1015625\n",
            "step = 400: Average Return = 543.9249877929688\n",
            "step = 600: loss = 8393.783203125\n",
            "step = 600: Average Return = 343.82000732421875\n",
            "step = 800: loss = 3414.2919921875\n",
            "step = 800: Average Return = 251.55499267578125\n",
            "step = 1000: loss = 4958.73388671875\n",
            "step = 1000: Average Return = 501.7349853515625\n",
            "step = 1200: loss = 3033.614501953125\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iVcmfkwTjhTK"
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "\n",
        "iterations = range(0, num_iterations + 1, eval_interval)\n",
        "plt.plot(iterations, returns)\n",
        "plt.ylabel('Average Return')\n",
        "plt.xlabel('Iterations')\n",
        "plt.ylim(top=250)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xFzyDMyjvgBf"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7fiPWog2vgH6"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pYl-ZxnLqwaK"
      },
      "source": [
        "def embed_mp4(filename):\n",
        "  \"\"\"Embeds an mp4 file in the notebook.\"\"\"\n",
        "  video = open(filename,'rb').read()\n",
        "  b64 = base64.b64encode(video)\n",
        "  tag = '''\n",
        "  <video width=\"640\" height=\"480\" controls>\n",
        "    <source src=\"data:video/mp4;base64,{0}\" type=\"video/mp4\">\n",
        "  Your browser does not support the video tag.\n",
        "  </video>'''.format(b64.decode())\n",
        "\n",
        "  return IPython.display.HTML(tag)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "u-PAZD2gq3de"
      },
      "source": [
        "import imageio\n",
        "def create_policy_eval_video(policy, filename, num_episodes=5, fps=30):\n",
        "  filename = filename + \".mp4\"\n",
        "  with imageio.get_writer(filename, fps=fps) as video:\n",
        "    env = make(\"hungry_geese\")\n",
        "    for _ in range(num_episodes):\n",
        "      time_step = eval_env.reset()\n",
        "      video.append_data(env.render())\n",
        "      while not time_step.is_last():\n",
        "        action_step = policy.action(time_step)\n",
        "        time_step = eval_env.step(action_step.action)\n",
        "        video.append_data(env.render())\n",
        "  return embed_mp4(filename)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TkSvuqmDrDmj"
      },
      "source": [
        "env.render\n",
        "#create_policy_eval_video(agent.post_process_policy, \"random-agent\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "i22e4nrXrL78"
      },
      "source": [
        "!sudo apt-get update\n",
        "!sudo apt-get install -y xvfb ffmpeg\n",
        "!pip install 'imageio==2.4.0'\n",
        "!pip install pyvirtualdisplay"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Hb6IdKdYrS3Y"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}